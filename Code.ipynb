{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da54610f",
   "metadata": {},
   "source": [
    "Synthetic ICH CT Generation - Generation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3393757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Synthetic Dataset/Synthetic ICH CT/Generation 1\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/ICH Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT.png'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479c475",
   "metadata": {},
   "source": [
    "Synthetic ICH CT Generation - Generation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20765701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Dataset (Synthetic)/Synthetic ICH CT/Generation 2\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/ICH Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT - 4.jpg'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91012f46",
   "metadata": {},
   "source": [
    "Synthetic ICH CT Generation - Generation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Dataset (Synthetic)/Synthetic ICH CT/Generation 3\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/ICH Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT - 4.jpg'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c722fa8",
   "metadata": {},
   "source": [
    "Synthetic Normal CT Generation - Generation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Dataset (Synthetic)/Synthetic Normal Brain CT/Generation 1\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/Normal Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT - 4.jpg'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290e1f7",
   "metadata": {},
   "source": [
    "Synthetic Normal CT Generation - Generation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cccea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Dataset (Synthetic)/Synthetic Normal Brain CT/Generation 2\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/Normal Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT - 4.jpg'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d19bb",
   "metadata": {},
   "source": [
    "Synthetic Normal CT Generation - Generation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "# Enable OpenCV multithreading for faster CPU performance\n",
    "cv2.setUseOptimized(True)\n",
    "cv2.setNumThreads(os.cpu_count())\n",
    "\n",
    "# ---- Super-resolution setup (4× → 2× chain for 8×) ----\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "\n",
    "device = torch.device(\"cpu\")  # force CPU\n",
    "\n",
    "# 4× model for final super-res\n",
    "rrdb4 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "sr4 = RealESRGANer(\n",
    "    scale=4,\n",
    "    model_path='RealESRGAN_x4plus.pth',\n",
    "    model=rrdb4,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "# 2× model for final super-res\n",
    "rrdb2 = RRDBNet(3, 3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
    "sr2 = RealESRGANer(\n",
    "    scale=2,\n",
    "    model_path='RealESRGAN_x2plus.pth',\n",
    "    model=rrdb2,\n",
    "    tile=0, tile_pad=10, pre_pad=0,\n",
    "    half=False, device=device\n",
    ")\n",
    "\n",
    "# ---- GAN setup ----\n",
    "batch_size = 16\n",
    "image_size = 64       # training on 64×64 slices\n",
    "nc, nz, ngf, ndf = 1, 100, 64, 64\n",
    "num_epochs, lr, beta1 = 100, 0.0002, 0.5\n",
    "\n",
    "out_dir = \"Dataset (Synthetic)/Synthetic Normal Brain CT/Generation 3\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.Grayscale(num_output_channels=nc),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"Dataset (East Cyprus Hospital)/Normal Brain CT\", transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "# ---- Load a real CT slice for histogram matching ----\n",
    "ref_ct_path = 'Reference CT - 4.jpg'\n",
    "ref_ct = cv2.imread(ref_ct_path, cv2.IMREAD_GRAYSCALE)\n",
    "if ref_ct is None:\n",
    "    raise FileNotFoundError(f\"Reference CT not found at {ref_ct_path}\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Post-processing helpers\n",
    "# ----------------------------------\n",
    "\n",
    "def denoise_nl_means(tensor_img, h=3, templateWindowSize=7, searchWindowSize=21):\n",
    "    np_img = tensor_img.squeeze().cpu().numpy()\n",
    "    np_img8 = ((np_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    denoised8 = cv2.fastNlMeansDenoising(np_img8,\n",
    "                                         None,\n",
    "                                         h=h,\n",
    "                                         templateWindowSize=templateWindowSize,\n",
    "                                         searchWindowSize=searchWindowSize)\n",
    "    denoised_f = denoised8.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(denoised_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def guided_bilateral_filter(np_img,\n",
    "                            d=5, sigmaColor=50, sigmaSpace=50,\n",
    "                            radius=5, eps=100.0):\n",
    "    \"\"\"\n",
    "    Light bilateral → (optional) guided filter for edge preservation.\n",
    "    \"\"\"\n",
    "    bf = cv2.bilateralFilter(np_img, d=d,\n",
    "                             sigmaColor=sigmaColor,\n",
    "                             sigmaSpace=sigmaSpace)\n",
    "    return bf\n",
    "\n",
    "def sharp_kernel_filter(tensor_img):\n",
    "    \"\"\"3×3 high-boost sharpening kernel (strong).\"\"\"\n",
    "    kernel = np.array([[-1, -1, -1],\n",
    "                       [-1,  9, -1],\n",
    "                       [-1, -1, -1]], dtype=np.float32)\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    sharp = cv2.filter2D(np_img, -1, kernel)\n",
    "    sharp = np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "    sharp_f = sharp.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(sharp_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def clahe_enhance(tensor_img, clipLimit=2.0, tileGridSize=(4,4)):\n",
    "    \"\"\"CLAHE with smaller tiles for stronger local contrast.\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    cl = clahe.apply(np_img)\n",
    "    cl_f = cl.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(cl_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "def match_histogram_tensor(tensor_img, ref_uint8):\n",
    "    \"\"\"Match histogram of tensor_img to ref_uint8 (both 8-bit).\"\"\"\n",
    "    np_img = (tensor_img.squeeze().cpu().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(np_img, ref_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    matched_f = matched.astype(np.float32) / 127.5 - 1.0\n",
    "    return torch.from_numpy(matched_f).unsqueeze(0).to(tensor_img.device)\n",
    "\n",
    "# ----------------------------------\n",
    "# DCGAN Generator & Discriminator\n",
    "# ----------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),        # 1→4\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),        # 4→8\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),        # 8→16\n",
    "            nn.ConvTranspose2d(ngf*2, ngf,   4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),   nn.ReLU(True),        # 16→32\n",
    "            nn.ConvTranspose2d(ngf,    nc,     4, 2, 1, bias=False),\n",
    "            nn.Tanh()                                     # 32→64\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc,   ndf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(ndf*8, 1,     4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion  = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# fixed noise for sampling\n",
    "num_samples = 400\n",
    "fixed_noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
    "\n",
    "# ----------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real = imgs.to(device)\n",
    "        b_size = real.size(0)\n",
    "        label_real = torch.ones(b_size, device=device)\n",
    "        label_fake = torch.zeros(b_size, device=device)\n",
    "\n",
    "        # Discriminator real loss\n",
    "        netD.zero_grad()\n",
    "        errD_real = criterion(netD(real), label_real)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # Discriminator fake loss\n",
    "        noise    = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_img = netG(noise)\n",
    "        errD_fake = criterion(netD(fake_img.detach()), label_fake)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Generator loss\n",
    "        netG.zero_grad()\n",
    "        errG = criterion(netD(fake_img), label_real)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[{epoch+1}/{num_epochs}][{i}/{len(dataloader)}] \"\n",
    "                  f\"Loss_D: {(errD_real+errD_fake).item():.4f} \"\n",
    "                  f\"Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    # ---- Sampling & saving after each epoch ----\n",
    "    with torch.no_grad():\n",
    "        raw = netG(fixed_noise).cpu()\n",
    "\n",
    "        # 1) Guided bilateral filter → filtered, compute noise map\n",
    "        filtered = torch.zeros_like(raw)\n",
    "        for idx in range(raw.size(0)):\n",
    "            np_img = (raw[idx].squeeze().numpy() * 127.5 + 127.5).astype(np.uint8)\n",
    "            out = guided_bilateral_filter(np_img)\n",
    "            tensor_out = torch.from_numpy((out.astype(np.float32)/127.5 - 1.0)) \\\n",
    "                            .unsqueeze(0).to(raw.device)\n",
    "            filtered[idx] = tensor_out\n",
    "\n",
    "        noise_map = raw - filtered   # retains high-freq detail\n",
    "\n",
    "        # 2) Sharpen → denoise → CLAHE → hist match → fake64\n",
    "        proc = torch.zeros_like(filtered)\n",
    "        for idx in range(filtered.size(0)):\n",
    "            img = filtered[idx]\n",
    "            img = sharp_kernel_filter(img)\n",
    "            img = denoise_nl_means(img, h=3)\n",
    "            img = clahe_enhance(img, clipLimit=2.0, tileGridSize=(4,4))\n",
    "            img = match_histogram_tensor(img, ref_ct)\n",
    "            proc[idx] = img\n",
    "        fake64 = proc\n",
    "\n",
    "        # visualize & save 64×64 grid\n",
    "        grid = utils.make_grid(fake64, nrow=20, padding=2, normalize=True)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(np.transpose(grid, (1,2,0)), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Epoch {epoch+1}\")\n",
    "        plt.show()\n",
    "        utils.save_image(fake64,\n",
    "                         os.path.join(out_dir, f\"epoch_{epoch+1}.png\"),\n",
    "                         normalize=True)\n",
    "\n",
    "        # 3) Final super-res + reinjection + 512×512 sharpen\n",
    "        if (epoch + 1) == num_epochs:\n",
    "            print(\"Applying Super-Resolution + reinjection + final sharpen…\")\n",
    "            alpha = 0.9\n",
    "            heavy_kernel = np.array([[-1, -1, -1],\n",
    "                                     [-1,  9, -1],\n",
    "                                     [-1, -1, -1]], dtype=np.float32)\n",
    "\n",
    "            for idx in range(fake64.size(0)):\n",
    "                pil64 = transforms.ToPILImage()(\n",
    "                        (fake64[idx]*0.5 + 0.5).clamp(0,1)\n",
    "                      ).convert('RGB')\n",
    "                arr64 = np.array(pil64)\n",
    "\n",
    "                out4, _ = sr4.enhance(arr64)\n",
    "                out8, _ = sr2.enhance(out4)\n",
    "\n",
    "                nm = noise_map[idx].squeeze().numpy()\n",
    "                nm_img = Image.fromarray(((nm*127.5)+127.5).astype(np.uint8))\n",
    "                nm_hr  = nm_img.resize((out8.shape[1], out8.shape[0]),\n",
    "                                       Image.BICUBIC)\n",
    "                nm_hr_f= (np.array(nm_hr).astype(np.float32)-127.5)/127.5\n",
    "\n",
    "                sr8 = out8.astype(np.float32)/255.0\n",
    "                combined = np.clip(sr8 + alpha * nm_hr_f[...,None], 0, 1)\n",
    "\n",
    "                final = (combined*255).astype(np.uint8)[...,0]\n",
    "                sharp_final = cv2.filter2D(final, -1, heavy_kernel)\n",
    "                final_gray = Image.fromarray(sharp_final)\n",
    "                final_gray.save(os.path.join(out_dir,\n",
    "                                             f\"sr8_epoch{epoch+1}_img{idx}.png\"))\n",
    "\n",
    "            print(\"Super-resolution + reinjection + final sharpen complete!\")\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1993f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit torch torchvision numpy Pillow scikit-image torchmetrics scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.exposure import match_histograms\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- Device --\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -- DCGAN Generator Definition --\n",
    "nz, ngf, nc = 100, 64, 1\n",
    "nrows = 8\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# -- Postprocessing Helpers --\n",
    "def match_histogram_tensor(tensor_img, ref_img_uint8):\n",
    "    img = tensor_img.squeeze().cpu().numpy()\n",
    "    img_uint8 = ((img + 1.0) * 127.5).astype(np.uint8)\n",
    "    matched = match_histograms(img_uint8, ref_img_uint8, channel_axis=None)\n",
    "    matched = np.clip(matched, 0, 255).astype(np.uint8)\n",
    "    f = matched.astype(np.float32)/127.5 - 1.0\n",
    "    return torch.from_numpy(f).unsqueeze(0)\n",
    "\n",
    "# -- Metric Functions --\n",
    "def compute_inception_score(images, resize=True):\n",
    "    is_metric = InceptionScore(feature=None, dims=2048)\n",
    "    return is_metric(images.to(device), resize=resize)\n",
    "\n",
    "\n",
    "def compute_fid(real_images, fake_images, resize=True):\n",
    "    fid_metric = FrechetInceptionDistance(feature=None, dims=2048)\n",
    "    fid_metric(real_images.to(device), real=True, resize=resize)\n",
    "    fid_metric(fake_images.to(device), real=False, resize=resize)\n",
    "    return fid_metric.compute()\n",
    "\n",
    "\n",
    "def compute_ssim_batch(real_imgs, fake_imgs):\n",
    "    scores = []\n",
    "    real = real_imgs.squeeze().cpu().numpy()\n",
    "    fake = fake_imgs.squeeze().cpu().numpy()\n",
    "    for r, f in zip(real, fake):\n",
    "        scores.append(ssim(r, f, data_range=2.0))\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# -- Classification AUC Evaluation --\n",
    "def evaluate_auc(real_dir, fake_images):\n",
    "    # Load real images and labels\n",
    "    dataset = datasets.ImageFolder(root=real_dir, transform=transforms.Compose([\n",
    "        transforms.Resize(64), transforms.Grayscale(), transforms.ToTensor()]))\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    X_real, y_real = [], []\n",
    "    for imgs, labels in loader:\n",
    "        X_real.append(imgs.view(imgs.size(0), -1).numpy())\n",
    "        y_real.append(labels.numpy())\n",
    "    X_real = np.vstack(X_real); y_real = np.hstack(y_real)\n",
    "    # Fake images flatten\n",
    "    X_fake = fake_images.view(fake_images.size(0), -1).cpu().numpy()\n",
    "    y_fake = np.ones(X_fake.shape[0]) * -1  # label synthetic as class -1\n",
    "    # binary labels: real=1, fake=0\n",
    "    X = np.vstack([X_real, X_fake]); y = np.hstack([np.ones_like(y_real), np.zeros_like(y_fake)])\n",
    "    # Train on real only\n",
    "    clf_real = LogisticRegression(max_iter=1000).fit(X_real, np.ones_like(y_real))\n",
    "    # Predict on real test\n",
    "    probs_real = clf_real.predict_proba(X_real)[:,1]\n",
    "    auc_real = roc_auc_score(np.ones_like(y_real), probs_real)\n",
    "    # Train on real+fake\n",
    "    clf_mix = LogisticRegression(max_iter=1000).fit(X, y)\n",
    "    probs_mix = clf_mix.predict_proba(X_real)[:,1]\n",
    "    auc_mix = roc_auc_score(np.ones_like(y_real), probs_mix)\n",
    "    fpr_real, tpr_real, _ = roc_curve(np.ones_like(y_real), probs_real)\n",
    "    fpr_mix, tpr_mix, _ = roc_curve(np.ones_like(y_real), probs_mix)\n",
    "    return {'AUC_real_only': auc_real, 'AUC_real+synthetic': auc_mix}, (fpr_real, tpr_real, fpr_mix, tpr_mix)\n",
    "\n",
    "# -- App UI --\n",
    "st.title(\"Synthetic CT Generator & Metrics Dashboard\")\n",
    "st.sidebar.header(\"Configuration\")\n",
    "\n",
    "# Input params\n",
    "ckpt = st.sidebar.file_uploader(\"Upload DCGAN Generator Checkpoint\", type=['pth','pt'])\n",
    "num_images = st.sidebar.slider(\"Number of Synthetic CTs\", 1, 400, 100)\n",
    "real_dir = st.sidebar.text_input(\"Path to Real CT ImageFolder\", \"./Dataset_Normal_CT\")\n",
    "ref_ct_file = st.sidebar.file_uploader(\"Reference CT for Hist Matching\", type=['png','jpg','jpeg'])\n",
    "\n",
    "# Load Generator\n",
    "netG = Generator().to(device)\n",
    "if ckpt:\n",
    "    state = torch.load(ckpt, map_location=device)\n",
    "    netG.load_state_dict(state)\n",
    "    st.sidebar.success(\"Generator loaded.\")\n",
    "\n",
    "# Read reference CT\n",
    "ref_uint8 = None\n",
    "if ref_ct_file:\n",
    "    ref_img = Image.open(ref_ct_file).convert('L')\n",
    "    ref_uint8 = np.array(ref_img)\n",
    "\n",
    "# Buttons\n",
    "generate = st.sidebar.button(\"Generate Synthetic CTs\")\n",
    "compute_metrics_btn = st.sidebar.button(\"Compute Metrics\")\n",
    "evaluate_auc_btn = st.sidebar.button(\"Evaluate AUC\")\n",
    "\n",
    "# Storage\n",
    "if 'synthetic' not in st.session_state:\n",
    "    st.session_state.synthetic = None\n",
    "\n",
    "# Generate synthetic CTs\n",
    "if generate:\n",
    "    st.info(\"Generating images...\")\n",
    "    noise = torch.randn(num_images, nz, 1, 1, device=device)\n",
    "    with torch.no_grad():\n",
    "        raw = netG(noise).cpu()\n",
    "    # Postprocessing: hist match if provided\n",
    "    if ref_uint8 is not None:\n",
    "        proc = torch.stack([match_histogram_tensor(img, ref_uint8) for img in raw])\n",
    "        fake = proc\n",
    "    else:\n",
    "        fake = raw\n",
    "    st.session_state.synthetic = fake\n",
    "    grid = make_grid(fake, nrow=nrows, normalize=True)\n",
    "    st.image(grid.permute(1,2,0), caption=\"Synthetic CTs\", use_column_width=True)\n",
    "\n",
    "# Compute and display metrics\n",
    "if compute_metrics_btn and st.session_state.synthetic is not None:\n",
    "    st.info(\"Computing metrics...\")\n",
    "    # Load real images\n",
    "    real_dataset = datasets.ImageFolder(root=real_dir, transform=transforms.Compose([\n",
    "        transforms.Resize(64), transforms.Grayscale(), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]))\n",
    "    real_loader = torch.utils.data.DataLoader(real_dataset, batch_size=num_images, shuffle=False)\n",
    "    real_imgs, _ = next(iter(real_loader))\n",
    "    fake_imgs = st.session_state.synthetic\n",
    "    # Normalize to [-1,1]\n",
    "    is_score, is_std = compute_inception_score(fake_imgs)\n",
    "    fid_score = compute_fid(real_imgs, fake_imgs)\n",
    "    ssim_score = compute_ssim_batch((real_imgs+1)/1, (fake_imgs+1)/1)\n",
    "    st.metric(\"Inception Score\", f\"{is_score:.3f} ± {is_std:.3f}\")\n",
    "    st.metric(\"FID\", f\"{fid_score:.3f}\")\n",
    "    st.metric(\"SSIM\", f\"{ssim_score:.3f}\")\n",
    "\n",
    "# Evaluate AUC\n",
    "if evaluate_auc_btn and st.session_state.synthetic is not None:\n",
    "    st.info(\"Evaluating AUC for classification task...\")\n",
    "    aucs, curves = evaluate_auc(real_dir, st.session_state.synthetic)\n",
    "    st.metric(\"AUC (Real Only)\", f\"{aucs['AUC_real_only']:.3f}\")\n",
    "    st.metric(\"AUC (Real + Synthetic)\", f\"{aucs['AUC_real+synthetic']:.3f}\")\n",
    "    fpr_r, tpr_r, fpr_m, tpr_m = curves\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr_r, tpr_r, label='Real Only')\n",
    "    ax.plot(fpr_m, tpr_m, label='Real+Synthetic')\n",
    "    ax.plot([0,1], [0,1], 'k--')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curves')\n",
    "    ax.legend()\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# Download synthetic\n",
    "if st.session_state.synthetic is not None:\n",
    "    buffer = io.BytesIO()\n",
    "    save_image(st.session_state.synthetic, buffer, nrow=nrows, normalize=True)\n",
    "    st.download_button(label=\"Download Grid of Synthetic CTs\",\n",
    "                       data=buffer.getvalue(), file_name=\"synthetic_cts.png\",\n",
    "                       mime=\"image/png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
